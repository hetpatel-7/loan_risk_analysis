labs(title = "Risk-Based Pricing Segments",
subtitle = "Credit Score vs. Interest Rate (K-Means k=3)",
x = "Credit Score (Higher is Better)",
y = "Interest Rate (Lower is Better)") +
theme_minimal() +
theme(legend.position = "bottom")
# 5. Interpret Centers
cat("\n--- Cluster Centers (Score vs Rate) ---\n")
kmeans_rate <- kmeans(df_cluster_rate, centers = 4, nstart = 25)
# 3. Prepare Plotting Data
df_plot_rate <- df %>%
select(credit_score, interest_rate) %>%
mutate(Cluster = as.factor(kmeans_rate$cluster))
# 4. Visualize
ggplot(df_plot_rate, aes(x = credit_score, y = interest_rate, color = Cluster)) +
geom_point(alpha = 0.6) +
# Format Y-axis as percentage (e.g., 10%)
scale_y_continuous(labels = function(x) paste0(x, "%")) +
labs(title = "Risk-Based Pricing Segments",
subtitle = "Credit Score vs. Interest Rate (K-Means k=3)",
x = "Credit Score (Higher is Better)",
y = "Interest Rate (Lower is Better)") +
theme_minimal() +
theme(legend.position = "bottom")
# 5. Interpret Centers
cat("\n--- Cluster Centers (Score vs Rate) ---\n")
kmeans_rate <- kmeans(df_cluster_rate, centers = 3, nstart = 25)
# 3. Prepare Plotting Data
df_plot_rate <- df %>%
select(credit_score, interest_rate) %>%
mutate(Cluster = as.factor(kmeans_rate$cluster))
# 4. Visualize
ggplot(df_plot_rate, aes(x = credit_score, y = interest_rate, color = Cluster)) +
geom_point(alpha = 0.6) +
# Format Y-axis as percentage (e.g., 10%)
scale_y_continuous(labels = function(x) paste0(x, "%")) +
labs(title = "Risk-Based Pricing Segments",
subtitle = "Credit Score vs. Interest Rate (K-Means k=3)",
x = "Credit Score (Higher is Better)",
y = "Interest Rate (Lower is Better)") +
theme_minimal() +
theme(legend.position = "bottom")
# 5. Interpret Centers
cat("\n--- Cluster Centers (Score vs Rate) ---\n")
# Graph 1: Who pays back the most? (Loan Repayment Rate by Employment)
# We calculate the % of people who paid back in each group
df_emp_rate <- df %>%
group_by(employment_status) %>%
summarise(repayment_rate = mean(loan_paid_back == "Paid"))
ggplot(df_emp_rate, aes(x = reorder(employment_status, repayment_rate), y = repayment_rate)) +
geom_col(fill = "#3498DB", width = 0.6) +
geom_text(aes(label = scales::percent(repayment_rate, accuracy = 0.1)), vjust = -0.5) +
scale_y_continuous(labels = scales::percent_format()) +
labs(title = "Loan Repayment Rate by Employment Status",
subtitle = "employed people are slightly more reliable than self-employed",
x = "Employment Status", y = "Repayment Rate") +
theme_minimal()
# Graph 2: Do educated people have better Credit Scores?
# Average Credit Score by Education Level
df_edu_score <- df %>%
group_by(education_level) %>%
summarise(avg_score = mean(credit_score))
ggplot(df_edu_score, aes(x = reorder(education_level, avg_score), y = avg_score)) +
geom_col(fill = "#2ECC71", width = 0.6) +
coord_cartesian(ylim = c(600, 750)) + # Zoom in to see differences
geom_text(aes(label = round(avg_score, 0)), vjust = -0.5) +
labs(title = "Average Credit Score by Education Level",
x = "Education Level", y = "Average Credit Score") +
theme_minimal()
# Graph 2: Do educated people have better Credit Scores?
# Average Credit Score by Education Level
df_edu_score <- df %>%
group_by(education_level) %>%
summarise(median_score = median(credit_score))
ggplot(df_edu_score, aes(x = reorder(education_level, avg_score), y = avg_score)) +
geom_col(fill = "#2ECC71", width = 0.6) +
coord_cartesian(ylim = c(600, 750)) + # Zoom in to see differences
geom_text(aes(label = round(avg_score, 0)), vjust = -0.5) +
labs(title = "Average Credit Score by Education Level",
x = "Education Level", y = "Average Credit Score") +
theme_minimal()
# Graph 3: Demographics Credit Analysis (Gender & Marital Status)
# We use a boxplot to show the spread of credit scores across groups
ggplot(df, aes(x = marital_status, y = credit_score, fill = gender)) +
geom_boxplot() +
labs(title = "Credit Score Distribution: Gender & Marital Status",
subtitle = "Check if specific demographic groups have lower scores",
x = "Marital Status", y = "Credit Score") +
theme_minimal() +
theme(legend.position = "top")
# Graph 2: Do educated people have better Credit Scores?
# Average Credit Score by Education Level
# 1. Calculate the Median
df_edu_score <- df %>%
group_by(education_level) %>%
summarise(median_score = median(credit_score))
# 2. Plot the Median
ggplot(df_edu_score, aes(x = reorder(education_level, median_score), y = median_score)) +
geom_col(fill = "#2ECC71", width = 0.6) +
coord_cartesian(ylim = c(600, 750)) + # Keep the zoom to see small differences
geom_text(aes(label = median_score), vjust = -0.5) +
labs(title = "Median Credit Score by Education Level",
x = "Education Level",
y = "Median Credit Score") +
theme_minimal()
# Graph 2: Do educated people have better Credit Scores?
# Average Credit Score by Education Level
df_edu_score <- df %>%
group_by(education_level) %>%
summarise(avg_score = mean(credit_score))
ggplot(df_edu_score, aes(x = reorder(education_level, avg_score), y = avg_score)) +
geom_col(fill = "#2ECC71", width = 0.6) +
coord_cartesian(ylim = c(600, 750)) + # Zoom in to see differences
geom_text(aes(label = round(avg_score, 0)), vjust = -0.5) +
labs(title = "Average Credit Score by Education Level",
x = "Education Level", y = "Average Credit Score") +
theme_minimal()
# Graph 4: The "Danger Zone" Scatter Plot (Income vs Loan Amount)
ggplot(df, aes(x = annual_income, y = loan_amount, color = loan_paid_back)) +
geom_point(alpha = 0.5, size = 1.5) +
scale_color_manual(values = c("Default" = "#E74C3C", "Paid" = "#3498DB")) +
scale_x_continuous(labels = dollar_format()) +
scale_y_continuous(labels = dollar_format()) +
labs(title = "Loan Status by Income & Loan Amount",
subtitle = "Red dots (Defaults) concentrate in High Loan/Low Income areas",
x = "Annual Income",
y = "Loan Amount",
color = "Status") +
theme_minimal() +
theme(legend.position = "top")
# Graph 5: Employment x Marital Status Risk Matrix
# We calculate the DEFAULT RATE (Risk) for every combination
risk_matrix <- df %>%
group_by(employment_status, marital_status) %>%
summarise(default_rate = mean(loan_paid_back == "Default"))
ggplot(risk_matrix, aes(x = marital_status, y = employment_status, fill = default_rate)) +
geom_tile(color = "white") +
geom_text(aes(label = scales::percent(default_rate, accuracy = 0.1)), color = "black") +
scale_fill_gradient(low = "#D6EAF8", high = "#E74C3C") + # Blue (Safe) to Red (Risky)
labs(title = "Risk Matrix: Probability of Default",
subtitle = "Redder cells indicate higher risk groups",
x = "Marital Status", y = "Employment Status", fill = "Default Risk") +
theme_minimal()
# --- E. Correlation Matrix ---
numeric_vars <- df %>% select_if(is.numeric)
corr_matrix <- cor(numeric_vars)
col_palette <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix, method = "color", col = col_palette(200),
type = "upper", order = "hclust",
addCoef.col = "black",
tl.col = "black", tl.srt = 45,
number.cex = 0.6,
diag = FALSE,
title = "Correlation Heatmap",
mar = c(0,0,1,0))
# 1. Select numeric variables but REMOVE the ones you don't want
numeric_vars <- df %>%
select_if(is.numeric) %>%
select(-age, -public_records, -num_of_open_accounts)
# 2. Calculate Correlation
corr_matrix <- cor(numeric_vars)
# 3. Create the Plot (No Numbers, Just Colors)
col_palette <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix,
method = "color",
col = col_palette(200),
type = "upper",
order = "hclust",
# REMOVED: addCoef.col = "black" (This removes the numbers)
tl.col = "black", tl.srt = 45, # Keep text labels black and rotated
diag = FALSE,                  # Hide the diagonal line
title = "Correlation Heatmap (Financial Metrics Only)",
mar = c(0,0,1,0))
# 1. Select numeric variables but REMOVE the ones you don't want
numeric_vars <- df %>%
select_if(is.numeric) %>%
select(-age, -public_records, -num_of_open_accounts, -clara_cluster)
# 2. Calculate Correlation
corr_matrix <- cor(numeric_vars)
# 3. Create the Plot (No Numbers, Just Colors)
col_palette <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix,
method = "color",
col = col_palette(200),
type = "upper",
order = "hclust",
# REMOVED: addCoef.col = "black" (This removes the numbers)
tl.col = "black", tl.srt = 45, # Keep text labels black and rotated
diag = FALSE,                  # Hide the diagonal line
title = "Correlation Heatmap (Financial Metrics Only)",
mar = c(0,0,1,0))
# 1. Select numeric variables but REMOVE the ones you don't want
numeric_vars <- df %>%
select_if(is.numeric) %>%
select(-age, -public_records, -num_of_open_accounts, -clara_cluster, -monthly_income)
# 2. Calculate Correlation
corr_matrix <- cor(numeric_vars)
# 3. Create the Plot (No Numbers, Just Colors)
col_palette <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix,
method = "color",
col = col_palette(200),
type = "upper",
order = "hclust",
# REMOVED: addCoef.col = "black" (This removes the numbers)
tl.col = "black", tl.srt = 45, # Keep text labels black and rotated
diag = FALSE,                  # Hide the diagonal line
title = "Correlation Heatmap (Financial Metrics Only)",
mar = c(0,0,1,0))
# ==============================================================================
# 0. SETUP & LIBRARIES
# ==============================================================================
# Install packages if you don't have them
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(caret)) install.packages("caret")          # For machine learning
if(!require(arules)) install.packages("arules")        # For association rules
if(!require(cluster)) install.packages("cluster")      # For clustering
if(!require(factoextra)) install.packages("factoextra") # For cluster viz
if(!require(rpart)) install.packages("rpart")          # For Decision Trees
if(!require(rpart.plot)) install.packages("rpart.plot") # For plotting trees
if(!require(corrplot)) install.packages("corrplot")    # For correlation plots
if(!require(scales)) install.packages("scales")        # For dollar formatting
# Load Data
df <- read.csv("loan_dataset_20000.csv", stringsAsFactors = TRUE)
# Basic Inspection
cat("Dataset Dimensions:\n")
dim(df)
cat("\nOverview of Data:\n")
glimpse(df)
# --- A. Data Cleaning ---
# Check for missing values
sum(is.na(df))
# Convert Target 'loan_paid_back' to a Factor for Classification
# 1 = Paid, 0 = Default
df$loan_paid_back <- factor(df$loan_paid_back, levels = c(0, 1), labels = c("Default", "Paid"))
# Plot 1: Target Distribution (Imbalance Check)
# WHY: To see if we have enough examples of 'Default' to train a model.
ggplot(df, aes(x = loan_paid_back, fill = loan_paid_back)) +
geom_bar() +
labs(title = "Distribution of Loan Status", x = "Status", y = "Count") +
theme_minimal()
# Plot 2: Credit Score vs. Loan Status
# WHY: To test the hypothesis that higher credit scores lead to fewer defaults.
ggplot(df, aes(x = loan_paid_back, y = credit_score, fill = loan_paid_back)) +
geom_boxplot() +
labs(title = "Credit Score Distribution by Loan Outcome", y = "Credit Score") +
theme_minimal()
# Graph 1: Who pays back the most? (Loan Repayment Rate by Employment)
# We calculate the % of people who paid back in each group
df_emp_rate <- df %>%
group_by(employment_status) %>%
summarise(repayment_rate = mean(loan_paid_back == "Paid"))
ggplot(df_emp_rate, aes(x = reorder(employment_status, repayment_rate), y = repayment_rate)) +
geom_col(fill = "#3498DB", width = 0.6) +
geom_text(aes(label = scales::percent(repayment_rate, accuracy = 0.1)), vjust = -0.5) +
scale_y_continuous(labels = scales::percent_format()) +
labs(title = "Loan Repayment Rate by Employment Status",
subtitle = "employed people are slightly more reliable than self-employed",
x = "Employment Status", y = "Repayment Rate") +
theme_minimal()
# Graph 2: Do educated people have better Credit Scores?
# Average Credit Score by Education Level
df_edu_score <- df %>%
group_by(education_level) %>%
summarise(avg_score = mean(credit_score))
ggplot(df_edu_score, aes(x = reorder(education_level, avg_score), y = avg_score)) +
geom_col(fill = "#2ECC71", width = 0.6) +
coord_cartesian(ylim = c(600, 750)) + # Zoom in to see differences
geom_text(aes(label = round(avg_score, 0)), vjust = -0.5) +
labs(title = "Average Credit Score by Education Level",
x = "Education Level", y = "Average Credit Score") +
theme_minimal()
# Graph 3: Demographics Credit Analysis (Gender & Marital Status)
# We use a boxplot to show the spread of credit scores across groups
ggplot(df, aes(x = marital_status, y = credit_score, fill = gender)) +
geom_boxplot() +
labs(title = "Credit Score Distribution: Gender & Marital Status",
subtitle = "Check if specific demographic groups have lower scores",
x = "Marital Status", y = "Credit Score") +
theme_minimal() +
theme(legend.position = "top")
# Graph 4: The "Danger Zone" Scatter Plot (Income vs Loan Amount)
ggplot(df, aes(x = annual_income, y = loan_amount, color = loan_paid_back)) +
geom_point(alpha = 0.5, size = 1.5) +
scale_color_manual(values = c("Default" = "#E74C3C", "Paid" = "#3498DB")) +
scale_x_continuous(labels = dollar_format()) +
scale_y_continuous(labels = dollar_format()) +
labs(title = "Loan Status by Income & Loan Amount",
subtitle = "Red dots (Defaults) concentrate in High Loan/Low Income areas",
x = "Annual Income",
y = "Loan Amount",
color = "Status") +
theme_minimal() +
theme(legend.position = "top")
# Graph 4: Employment x Marital Status Risk Matrix
# We calculate the DEFAULT RATE (Risk) for every combination
risk_matrix <- df %>%
group_by(employment_status, marital_status) %>%
summarise(default_rate = mean(loan_paid_back == "Default"))
ggplot(risk_matrix, aes(x = marital_status, y = employment_status, fill = default_rate)) +
geom_tile(color = "white") +
geom_text(aes(label = scales::percent(default_rate, accuracy = 0.1)), color = "black") +
scale_fill_gradient(low = "#D6EAF8", high = "#E74C3C") + # Blue (Safe) to Red (Risky)
labs(title = "Risk Matrix: Probability of Default",
subtitle = "Redder cells indicate higher risk groups",
x = "Marital Status", y = "Employment Status", fill = "Default Risk") +
theme_minimal()
# --- D. Correlation Matrix ---
# 1. Select numeric variables but REMOVE the ones you don't want
numeric_vars <- df %>%
select_if(is.numeric) %>%
select(-age, -public_records, -num_of_open_accounts, -clara_cluster, -monthly_income)
# 2. Calculate Correlation
corr_matrix <- cor(numeric_vars)
# 3. Create the Plot (No Numbers, Just Colors)
col_palette <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix,
method = "color",
col = col_palette(200),
type = "upper",
order = "hclust",
# REMOVED: addCoef.col = "black" (This removes the numbers)
tl.col = "black", tl.srt = 45, # Keep text labels black and rotated
diag = FALSE,                  # Hide the diagonal line
title = "Correlation Heatmap",
mar = c(0,0,1,0))
# --- D. Correlation Matrix ---
# 1. Select numeric variables but REMOVE the ones you don't want
numeric_vars <- df %>%
select_if(is.numeric) %>%
select(-age, -public_records, -num_of_open_accounts, -monthly_income)
# 2. Calculate Correlation
corr_matrix <- cor(numeric_vars)
# 3. Create the Plot (No Numbers, Just Colors)
col_palette <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix,
method = "color",
col = col_palette(200),
type = "upper",
order = "hclust",
# REMOVED: addCoef.col = "black" (This removes the numbers)
tl.col = "black", tl.srt = 45, # Keep text labels black and rotated
diag = FALSE,                  # Hide the diagonal line
title = "Correlation Heatmap",
mar = c(0,0,1,0))
# Step 1: Discretization (Binning)
# Convert numbers (Income, Score) into categories (High, Low)
df_arules <- df %>%
mutate(
Income_Group = discretize(annual_income, method = "frequency", categories = 3, labels = c("Low", "Medium", "High")),
Credit_Group = discretize(credit_score, method = "frequency", categories = 3, labels = c("Poor", "Fair", "Good")),
DTI_Group = discretize(debt_to_income_ratio, method = "frequency", categories = 3, labels = c("Low_Risk", "Med_Risk", "High_Risk"))
) %>%
select(education_level, employment_status, Income_Group, Credit_Group, DTI_Group, loan_paid_back)
# --- Helper Function to Print Range Values Nicely ---
print_nice_ranges <- function(column_name, labels, decimals = 0) {
breaks <- attr(df_arules[[column_name]], "discretized:breaks")
cat(paste0("\n--- Ranges for ", column_name, " ---\n"))
for(i in 1:length(labels)) {
start <- format(round(breaks[i], decimals), big.mark=",", scientific=FALSE, nsmall=decimals)
end   <- format(round(breaks[i+1], decimals), big.mark=",", scientific=FALSE, nsmall=decimals)
cat(sprintf("%-10s: %s to %s\n", labels[i], start, end))
}
}
# Print the exact dollar/score ranges for your report
print_nice_ranges("Income_Group", c("Low", "Medium", "High"), decimals=0)
print_nice_ranges("Credit_Group", c("Poor", "Fair", "Good"), decimals=0)
print_nice_ranges("DTI_Group", c("Low_Risk", "Med_Risk", "High_Risk"), decimals=2)
# Step 2: Run Apriori Algorithm
trans <- as(df_arules, "transactions")
# Example 1: General Rules
# Finding frequent patterns with at least 10% support and 50% confidence
rules_general <- apriori(trans, parameter = list(supp = 0.1, conf = 0.5, minlen=2))
cat("\n--- General Association Rules ---\n")
inspect(head(sort(rules_general, by = "lift"), 5))
# Example 2: Rules Specific to DEFAULTS
# "What conditions strongly imply a Default?"
# Corrected Rule Mining for Defaults
rules_default <- apriori(trans,
parameter = list(supp = 0.01, conf = 0.1, minlen=2),
appearance = list(default = "lhs", rhs = "loan_paid_back=Default"))
cat("\n--- Rules Predicting Default ---\n")
inspect(head(sort(rules_default, by = "lift"), 5))
# Step 1: Split Data (70% Train, 30% Test)
set.seed(123)
trainIndex <- createDataPartition(df$loan_paid_back, p = 0.7, list = FALSE)
train_data <- df[trainIndex, ]
test_data <- df[-trainIndex, ]
# --- Method A: Logistic Regression ---
# Why: Highly interpretable. Gives us the "Odds Ratio" of default.
# We predict 'loan_paid_back' using Credit Score, Income, DTI, and Loan Term
model_glm <- glm(loan_paid_back ~ credit_score + annual_income + debt_to_income_ratio + loan_term,
data = train_data, family = "binomial")
# Predict on Test Data
prob_glm <- predict(model_glm, test_data, type = "response")
pred_glm <- ifelse(prob_glm > 0.65, "Paid", "Default")
pred_glm <- factor(pred_glm, levels = c("Default", "Paid"))
cat("\n--- Logistic Regression Performance ---\n")
# Show Accuracy, Precision, Recall, F1
confusionMatrix(pred_glm, test_data$loan_paid_back, mode = "prec_recall")
# --- Method B: Decision Tree ---
# Why: Non-linear and easy to visualize. Handles mixed data types well.
model_tree <- rpart(loan_paid_back ~ ., data = train_data, method = "class")
# Plot the Tree (Look for this in your 'Plots' tab in RStudio)
rpart.plot(model_tree, main = "Decision Tree for Loan Default")
# Predict
pred_tree <- predict(model_tree, test_data, type = "class")
cat("\n--- Decision Tree Performance ---\n")
cm_tree <- confusionMatrix(pred_tree, test_data$loan_paid_back, mode = "prec_recall")
print(cm_tree)
# Graph 4: The "Danger Zone" Scatter Plot (Defaults Only)
# Filter the data to get only Defaulters
df_defaults_only <- df %>% filter(loan_paid_back == "Default")
ggplot(df_defaults_only, aes(x = annual_income, y = loan_amount)) +
# Set color manually to Red since we only have one group now
geom_point(color = "#E74C3C", alpha = 0.5, size = 1.5) +
scale_x_continuous(labels = dollar_format()) +
scale_y_continuous(labels = dollar_format()) +
labs(title = "Loan Status by Income & Loan Amount (Defaults Only)",
subtitle = "Visualizing the 'Danger Zone' - High Loan vs Low Income",
x = "Annual Income",
y = "Loan Amount") +
theme_minimal()
ggplot(df_defaults_only, aes(x = annual_income, y = loan_amount)) +
# Set color manually to Red since we only have one group now
geom_point(color = "#E74C3C", alpha = 0.5, size = 1.5) +
scale_x_continuous(labels = dollar_format()) +
scale_y_continuous(labels = dollar_format()) +
labs(title = "Loan Status by Income & Loan Amount (Defaults Only)",
subtitle = "Visualizing the 'Danger Zone'",
x = "Annual Income",
y = "Loan Amount") +
theme_minimal()
# Prepare Data: Income vs Loan Amount
df_cluster_2var <- df %>%
select(annual_income, loan_amount) %>%
scale()
# --- Method A: CLARA (Robust Clustering) ---
set.seed(123)
clara_result <- clara(df_cluster_2var, k = 4, samples = 50, pamLike = TRUE)
# Visualize Clusters
fviz_cluster(clara_result,
data = df_cluster_2var,
geom = "point",
ellipse.type = "convex",
ggtheme = theme_minimal(),
main = "Customer Segments (CLARA)")
# Interpret Clusters (Real Dollar Values)
df$clara_cluster <- clara_result$clustering
cat("\n--- CLARA Cluster Profiles (Median Values) ---\n")
print(aggregate(cbind(annual_income, loan_amount) ~ clara_cluster, data = df, FUN = median))
# 1. Select & Scale Data
df_cluster_rate <- df %>%
select(credit_score, interest_rate) %>%
scale()
# 2. Run K-Means (k=3)
# We expect to see diagonal bands (High Score/Low Rate vs Low Score/High Rate)
set.seed(123)
kmeans_rate <- kmeans(df_cluster_rate, centers = 3, nstart = 25)
# 3. Prepare Plotting Data
df_plot_rate <- df %>%
select(credit_score, interest_rate) %>%
mutate(Cluster = as.factor(kmeans_rate$cluster))
# 4. Visualize
ggplot(df_plot_rate, aes(x = credit_score, y = interest_rate, color = Cluster)) +
geom_point(alpha = 0.6) +
# Format Y-axis as percentage (e.g., 10%)
scale_y_continuous(labels = function(x) paste0(x, "%")) +
labs(title = "Risk-Based Pricing Segments",
subtitle = "Credit Score vs. Interest Rate (K-Means k=3)",
x = "Credit Score (Higher is Better)",
y = "Interest Rate (Lower is Better)") +
theme_minimal() +
theme(legend.position = "bottom")
# 5. Interpret Centers
cat("\n--- Cluster Centers (Score vs Rate) ---\n")
print(aggregate(cbind(credit_score, interest_rate) ~ Cluster, data = df_plot_rate, FUN = mean))
# Custom Binning based on Clustering Results
df_arules <- df %>%
mutate(
# 1. Income: Using your CLARA findings (< 37k, 37k-78k, > 78k)
Income_Group = cut(annual_income,
breaks = c(-Inf, 37000, 78000, Inf),
labels = c("Low", "Medium", "High")),
# 2. Credit Score: Using your K-Means centers (< 638, 638-715, > 715)
Credit_Group = cut(credit_score,
breaks = c(-Inf, 638, 715, Inf),
labels = c("Poor", "Fair", "Good")),
# 3. DTI: We keep this automatic (frequency) as we didn't cluster on it
DTI_Group = discretize(debt_to_income_ratio, method = "frequency",
categories = 3, labels = c("Low_Risk", "Med_Risk", "High_Risk"))
) %>%
select(education_level, employment_status, Income_Group, Credit_Group, DTI_Group, loan_paid_back)
# --- Verify the New Counts ---
# Check how many people fall into your new "Cluster-Based" categories
cat("\n--- New Group Counts (Derived from Clustering) ---\n")
cat("Income Groups:\n")
print(table(df_arules$Income_Group))
cat("\nCredit Groups:\n")
print(table(df_arules$Credit_Group))
# --- Run Rule Mining Again ---
trans <- as(df_arules, "transactions")
# 1. General Rules
rules_general <- apriori(trans, parameter = list(supp = 0.1, conf = 0.5, minlen=2))
cat("\n--- General Association Rules (New Bins) ---\n")
inspect(head(sort(rules_general, by = "lift"), 5))
# 2. Default Rules (The ones you care about)
rules_default <- apriori(trans,
parameter = list(supp = 0.01, conf = 0.1, minlen=2),
appearance = list(default = "lhs", rhs = "loan_paid_back=Default"))
cat("\n--- Top Rules Predicting Default (New Bins) ---\n")
inspect(head(sort(rules_default, by = "lift"), 5))
